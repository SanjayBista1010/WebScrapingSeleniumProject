name: Run Scraper

# Trigger every 10 minutes and allow manual runs
on:
  schedule:
    - cron: '*/10 * * * *'  # every 10 minutes
  workflow_dispatch:

jobs:
  scraper-job:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2️⃣ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 3️⃣ Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install selenium webdriver-manager beautifulsoup4 lxml requests

      # 4️⃣ List files (optional, for debugging)
      - name: List files
        run: |
          pwd
          ls -R

      # 5️⃣ Run scraper (main.py already has random delay)
      - name: Run scraper
        run: python src/main.py

      # 6️⃣ Upload logs
      - name: Upload logs
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs
          path: logs/

      # 7️⃣ Upload headlines CSV
      - name: Upload headlines
        uses: actions/upload-artifact@v3
        with:
          name: headlines
          path: data/headlines.csv
